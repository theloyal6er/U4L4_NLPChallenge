{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import state_union, stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     /Users/jasonpaik9/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/state_union.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('state_union')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1945-Truman.txt',\n",
       " '1946-Truman.txt',\n",
       " '1947-Truman.txt',\n",
       " '1948-Truman.txt',\n",
       " '1949-Truman.txt',\n",
       " '1950-Truman.txt',\n",
       " '1951-Truman.txt',\n",
       " '1953-Eisenhower.txt',\n",
       " '1954-Eisenhower.txt',\n",
       " '1955-Eisenhower.txt',\n",
       " '1956-Eisenhower.txt',\n",
       " '1957-Eisenhower.txt',\n",
       " '1958-Eisenhower.txt',\n",
       " '1959-Eisenhower.txt',\n",
       " '1960-Eisenhower.txt',\n",
       " '1961-Kennedy.txt',\n",
       " '1962-Kennedy.txt',\n",
       " '1963-Johnson.txt',\n",
       " '1963-Kennedy.txt',\n",
       " '1964-Johnson.txt',\n",
       " '1965-Johnson-1.txt',\n",
       " '1965-Johnson-2.txt',\n",
       " '1966-Johnson.txt',\n",
       " '1967-Johnson.txt',\n",
       " '1968-Johnson.txt',\n",
       " '1969-Johnson.txt',\n",
       " '1970-Nixon.txt',\n",
       " '1971-Nixon.txt',\n",
       " '1972-Nixon.txt',\n",
       " '1973-Nixon.txt',\n",
       " '1974-Nixon.txt',\n",
       " '1975-Ford.txt',\n",
       " '1976-Ford.txt',\n",
       " '1977-Ford.txt',\n",
       " '1978-Carter.txt',\n",
       " '1979-Carter.txt',\n",
       " '1980-Carter.txt',\n",
       " '1981-Reagan.txt',\n",
       " '1982-Reagan.txt',\n",
       " '1983-Reagan.txt',\n",
       " '1984-Reagan.txt',\n",
       " '1985-Reagan.txt',\n",
       " '1986-Reagan.txt',\n",
       " '1987-Reagan.txt',\n",
       " '1988-Reagan.txt',\n",
       " '1989-Bush.txt',\n",
       " '1990-Bush.txt',\n",
       " '1991-Bush-1.txt',\n",
       " '1991-Bush-2.txt',\n",
       " '1992-Bush.txt',\n",
       " '1993-Clinton.txt',\n",
       " '1994-Clinton.txt',\n",
       " '1995-Clinton.txt',\n",
       " '1996-Clinton.txt',\n",
       " '1997-Clinton.txt',\n",
       " '1998-Clinton.txt',\n",
       " '1999-Clinton.txt',\n",
       " '2000-Clinton.txt',\n",
       " '2001-GWBush-1.txt',\n",
       " '2001-GWBush-2.txt',\n",
       " '2002-GWBush.txt',\n",
       " '2003-GWBush.txt',\n",
       " '2004-GWBush.txt',\n",
       " '2005-GWBush.txt',\n",
       " '2006-GWBush.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_union.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get speech by GWBush and Reagan\n",
    "bush = state_union.raw('2002-GWBush.txt')\n",
    "reagan = state_union.raw('1984-Reagan.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parse the data\n",
    "nlp = spacy.load('en')\n",
    "bush_doc = nlp(bush)\n",
    "reagan_doc = nlp(reagan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(STATE, OF, THE, UNION, ADDRESS, OF, THE, PRES...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(January, 29, ,, 2002, \\n\\n, THE, PRESIDENT, :...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Mr., Speaker, ,, Vice, President, Cheney, ,, ...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Yet, the, state, of, our, Union, has, never, ...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((, Applause, ., ), \\n)</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(We, last, met, in, an, hour, of, shock, and, ...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(In, four, short, months, ,, our, nation, has,...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>((, Applause, ., ), \\n)</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(The, American, flag, flies, again, over, our,...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Terrorists, who, once, occupied, Afghanistan,...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0     1\n",
       "0  (STATE, OF, THE, UNION, ADDRESS, OF, THE, PRES...  Bush\n",
       "1  (January, 29, ,, 2002, \\n\\n, THE, PRESIDENT, :...  Bush\n",
       "2  (Mr., Speaker, ,, Vice, President, Cheney, ,, ...  Bush\n",
       "3  (Yet, the, state, of, our, Union, has, never, ...  Bush\n",
       "4                            ((, Applause, ., ), \\n)  Bush\n",
       "5  (We, last, met, in, an, hour, of, shock, and, ...  Bush\n",
       "6  (In, four, short, months, ,, our, nation, has,...  Bush\n",
       "7                            ((, Applause, ., ), \\n)  Bush\n",
       "8  (The, American, flag, flies, again, over, our,...  Bush\n",
       "9  (Terrorists, who, once, occupied, Afghanistan,...  Bush"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Group the data between sentences and the person who delivered it\n",
    "bush_sents = [[sent,'Bush'] for sent in bush_doc.sents]\n",
    "reagan_sents = [[sent,'Reagan'] for sent in reagan_doc.sents]\n",
    "## Put them together\n",
    "sentences = pd.DataFrame(bush_sents + reagan_sents)\n",
    "sentences.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE OF THE UNION ADDRESS OF THE PRESIDENT TO THE JOINT SESSION OF CONGRESS\n",
      " \n",
      "January 29, 2002\n",
      "\n",
      "THE PRESIDENT:  Thank you very much.  Mr. Speaker, Vice President Cheney, members of Congress, distinguished guests, fellow citizens:  As we gather tonight, our nation is at war, our economy is in recession, and the civilized world faces unprecedented dangers.  Yet the state of our Union has never been stronger.  (Applause.) \n",
      "We last met in an hour of shock and\n",
      "\n",
      "GWBush speech length: 5013\n"
     ]
    }
   ],
   "source": [
    "print(bush_doc[:100])\n",
    "print('\\nGWBush speech length:', len(bush_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRESIDENT RONALD REAGAN'S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS ON THE STATE OF THE UNION\n",
      " \n",
      "January 25, 1984\n",
      "\n",
      "Mr. Speaker, Mr. President, distinguished Members of the Congress, honored guests, and fellow citizens:\n",
      "Once again, in keeping with time-honored tradition, I have come to report to you on the state of the Union, and I'm pleased to report that America is much improved, and there's good reason to believe that improvement will continue through the days to come.\n",
      "You\n",
      "\n",
      "RReagan speech length: 5815\n"
     ]
    }
   ],
   "source": [
    "print(reagan_doc[:100])\n",
    "print('\\nRReagan speech length:', len(reagan_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bags of Words - Features\n",
    "\n",
    "I wanted to split the texts between each of the speeches and see which words were most frequently used by each of presidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a bag of words function for each piece of text\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # filter out punctuation and stop words\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return most common words\n",
    "    return [item[0] for item in Counter(allwords).most_common(500)]\n",
    "\n",
    "# Get bags \n",
    "bush_words = bag_of_words(bush_doc)\n",
    "reagan_words = bag_of_words(reagan_doc)\n",
    "\n",
    "# Combine bags to create common set of unique words\n",
    "common_words = set(bush_words + reagan_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create BoW dataframe using common words and sentences\n",
    "def bow_features(sentences, common_words):\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentences in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentences\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nation</th>\n",
       "      <th>friendship</th>\n",
       "      <th>agree</th>\n",
       "      <th>private</th>\n",
       "      <th>overcoming</th>\n",
       "      <th>helicopter</th>\n",
       "      <th>shock</th>\n",
       "      <th>year</th>\n",
       "      <th>evening</th>\n",
       "      <th>Fi</th>\n",
       "      <th>...</th>\n",
       "      <th>military</th>\n",
       "      <th>unfair</th>\n",
       "      <th>cell</th>\n",
       "      <th>intelligence</th>\n",
       "      <th>moment</th>\n",
       "      <th>transportation</th>\n",
       "      <th>privilege</th>\n",
       "      <th>leadership</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(STATE, OF, THE, UNION, ADDRESS, OF, THE, PRES...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(January, 29, ,, 2002, \\n\\n, THE, PRESIDENT, :...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Mr., Speaker, ,, Vice, President, Cheney, ,, ...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Yet, the, state, of, our, Union, has, never, ...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>((, Applause, ., ), \\n)</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 812 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  nation friendship agree private overcoming helicopter shock year evening Fi  \\\n",
       "0      0          0     0       0          0          0     0    0       0  0   \n",
       "1      0          0     0       0          0          0     0    0       0  0   \n",
       "2      1          0     0       0          0          0     0    0       0  0   \n",
       "3      0          0     0       0          0          0     0    0       0  0   \n",
       "4      0          0     0       0          0          0     0    0       0  0   \n",
       "\n",
       "      ...     military unfair cell intelligence moment transportation  \\\n",
       "0     ...            0      0    0            0      0              0   \n",
       "1     ...            0      0    0            0      0              0   \n",
       "2     ...            0      0    0            0      0              0   \n",
       "3     ...            0      0    0            0      0              0   \n",
       "4     ...            0      0    0            0      0              0   \n",
       "\n",
       "  privilege leadership                                      text_sentence  \\\n",
       "0         0          0  (STATE, OF, THE, UNION, ADDRESS, OF, THE, PRES...   \n",
       "1         0          0  (January, 29, ,, 2002, \\n\\n, THE, PRESIDENT, :...   \n",
       "2         0          0  (Mr., Speaker, ,, Vice, President, Cheney, ,, ...   \n",
       "3         0          0  (Yet, the, state, of, our, Union, has, never, ...   \n",
       "4         0          0                            ((, Applause, ., ), \\n)   \n",
       "\n",
       "  text_source  \n",
       "0        Bush  \n",
       "1        Bush  \n",
       "2        Bush  \n",
       "3        Bush  \n",
       "4        Bush  \n",
       "\n",
       "[5 rows x 812 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create bow features \n",
    "bow = bow_features(sentences, common_words)\n",
    "bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grab sentence level documents in NLTK\n",
    "bush_1 = state_union.sents('2002-GWBush.txt')\n",
    "reagan_1 = state_union.sents('1984-Reagan.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of text \n",
    "reagan_list = [\" \".join(sent) for sent in reagan_1]\n",
    "bush_list = [\" \".join(sent) for sent in bush_1]\n",
    "joined = reagan_list + bush_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, \n",
    "                             min_df=2, \n",
    "                             stop_words='english',   \n",
    "                             use_idf=True,\n",
    "                             norm=u'l2', \n",
    "                             smooth_idf=True \n",
    "                            )\n",
    "\n",
    "tfidf = vectorizer.fit_transform(joined).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning Models\n",
    "\n",
    "I wanted to take the text to create features against cross validation. I also wanted to take this framework against the model of testing with Logistic Regression, Random Forest, and Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Specify model inputs for each feature set\n",
    "\n",
    "# BoW\n",
    "X_bow = bow.drop(['text_sentence', 'text_source'], 1)\n",
    "Y_bow = bow['text_source']\n",
    "\n",
    "# Tfidf\n",
    "X_tfidf = tfidf\n",
    "Y_tfidf = ['Reagan']*len(reagan_list) + ['Bush']*len(bush_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Logistic Regression Scores:  [0.95       0.925      0.95833333 0.95       0.91596639]\n",
      "Avg Score: 0.9398599439775911\n",
      "\n",
      "Tfidf Logistic Regression Scores: [0.73504274 0.76068376 0.8034188  0.75       0.63793103]\n",
      "Avg Score: 0.7374152667256115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# BoW\n",
    "lr = LogisticRegression()\n",
    "lr_bow = lr.fit(X_bow, Y_bow)\n",
    "print('BoW Logistic Regression Scores: ', cross_val_score(lr_bow, X_bow, Y_bow, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(lr_bow, X_bow, Y_bow, cv=5)))\n",
    "\n",
    "# Tfidf\n",
    "lr = LogisticRegression()\n",
    "lr_tfidf = lr.fit(X_tfidf, Y_tfidf)\n",
    "print('\\nTfidf Logistic Regression Scores:', cross_val_score(lr_tfidf, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(lr_tfidf, X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Random Forest Scores:  [0.925      0.93333333 0.95833333 0.94166667 0.92436975]\n",
      "Avg Score: 0.9398319327731093\n",
      "\n",
      "Tfidf Random Forest Scores: [0.74358974 0.75213675 0.76923077 0.73275862 0.6637931 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Score: 0.7443560271146479\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "# BoW\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc_bow = rfc.fit(X_bow, Y_bow)\n",
    "print('BoW Random Forest Scores: ', cross_val_score(rfc_bow, X_bow, Y_bow, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(rfc_bow, X_bow, Y_bow, cv=5)))\n",
    "\n",
    "# Tfidf\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc_tfidf = rfc.fit(X_tfidf, Y_tfidf)\n",
    "print('\\nTfidf Random Forest Scores:', cross_val_score(rfc_tfidf, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(rfc_tfidf, X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bow Gradient Boosting Scores: [0.95       0.91666667 0.96666667 0.95833333 0.91596639]\n",
      "Avg Score: 0.9432072829131654\n",
      "\n",
      "Tfidf Gradient Boosting Scores: [0.74358974 0.72649573 0.75213675 0.75       0.62931034]\n",
      "Avg Score: 0.7151635720601238\n"
     ]
    }
   ],
   "source": [
    "# BoW\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf_bow = clf.fit(X_bow, Y_bow)\n",
    "print('Bow Gradient Boosting Scores:', cross_val_score(clf_bow, X_bow,Y_bow, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(clf_bow, X_bow, Y_bow, cv=5)))\n",
    "\n",
    "# Tfidf\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf_tfidf = clf.fit(X_tfidf, Y_tfidf)\n",
    "print('\\nTfidf Gradient Boosting Scores:', cross_val_score(clf_tfidf, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(clf_tfidf, X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick a model and attempt to boost the accuracy by 5%\n",
    "\n",
    "Logistic regression - how to improve these accuracies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase BoW size\n",
    "\n",
    "# Update function to include 1000 most common words\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # filter out punctuation and stop words\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return most common words\n",
    "    return [item[0] for item in Counter(allwords).most_common(1000)]\n",
    "\n",
    "# Get bags \n",
    "bush_words = bag_of_words(bush_doc)\n",
    "reagan_words = bag_of_words(reagan_doc)\n",
    "\n",
    "# Combine bags to create common set of unique words\n",
    "common_words = set(bush_words + reagan_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bow features \n",
    "big_bow = bow_features(sentences, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deny</th>\n",
       "      <th>nation</th>\n",
       "      <th>call</th>\n",
       "      <th>understanding</th>\n",
       "      <th>try</th>\n",
       "      <th>risk</th>\n",
       "      <th>dictate</th>\n",
       "      <th>shareholder</th>\n",
       "      <th>pose</th>\n",
       "      <th></th>\n",
       "      <th>...</th>\n",
       "      <th>life</th>\n",
       "      <th>Age</th>\n",
       "      <th>unfair</th>\n",
       "      <th>servitude</th>\n",
       "      <th>intelligence</th>\n",
       "      <th>2,500</th>\n",
       "      <th>improved</th>\n",
       "      <th>pain</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(STATE, OF, THE, UNION, ADDRESS, OF, THE, PRES...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(January, 29, ,, 2002, \\n\\n, THE, PRESIDENT, :...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Mr., Speaker, ,, Vice, President, Cheney, ,, ...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Yet, the, state, of, our, Union, has, never, ...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>((, Applause, ., ), \\n)</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1589 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  deny nation call understanding try risk dictate shareholder pose     \\\n",
       "0    0      0    0             0   0    0       0           0    0  0   \n",
       "1    0      0    0             0   0    0       0           0    0  2   \n",
       "2    0      1    0             0   0    0       0           0    0  2   \n",
       "3    0      0    0             0   0    0       0           0    0  1   \n",
       "4    0      0    0             0   0    0       0           0    0  0   \n",
       "\n",
       "      ...     life Age unfair servitude intelligence 2,500 improved pain  \\\n",
       "0     ...        0   0      0         0            0     0        0    0   \n",
       "1     ...        0   0      0         0            0     0        0    0   \n",
       "2     ...        0   0      0         0            0     0        0    0   \n",
       "3     ...        0   0      0         0            0     0        0    0   \n",
       "4     ...        0   0      0         0            0     0        0    0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (STATE, OF, THE, UNION, ADDRESS, OF, THE, PRES...        Bush  \n",
       "1  (January, 29, ,, 2002, \\n\\n, THE, PRESIDENT, :...        Bush  \n",
       "2  (Mr., Speaker, ,, Vice, President, Cheney, ,, ...        Bush  \n",
       "3  (Yet, the, state, of, our, Union, has, never, ...        Bush  \n",
       "4                            ((, Applause, ., ), \\n)        Bush  \n",
       "\n",
       "[5 rows x 1589 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW (big) Logistic Regression Scores:  [0.94166667 0.925      0.95833333 0.95       0.91596639]\n",
      "Avg. Score  0.9381932773109245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Make new X and Y inputs\n",
    "X_big_bow = big_bow.drop(['text_sentence', 'text_source'], 1)\n",
    "Y_big_bow = big_bow['text_source']\n",
    "\n",
    "# Rerun BoW\n",
    "lr = LogisticRegression()\n",
    "lr_big_bow = lr.fit(X_big_bow, Y_big_bow)\n",
    "print('BoW (big) Logistic Regression Scores: ', cross_val_score(lr_big_bow, X_big_bow, Y_big_bow, cv=5))\n",
    "print('Avg. Score ', np.mean(cross_val_score(lr_big_bow, X_big_bow, Y_big_bow, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update function, go back to 500 most common words and add in punctuation\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # filter out punctuation and stop words\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_stop]\n",
    "                   \n",
    "    # Return most common words\n",
    "    return [item[0] for item in Counter(allwords).most_common(500)]\n",
    "\n",
    "# Get bags \n",
    "bush_words = bag_of_words(bush_doc)\n",
    "reagan_words = bag_of_words(reagan_doc)\n",
    "\n",
    "# Combine bags to create common set of unique words\n",
    "common_words = set(bush_words + reagan_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bow features \n",
    "bow = bow_features(sentences, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regenerate model features\n",
    "X_bow = bow.drop(['text_sentence', 'text_source'], 1)\n",
    "Y_bow = bow['text_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW #3 - Logistic Regression Scores:  [0.95       0.925      0.95833333 0.95       0.91596639]\n",
      "Avg. Score  0.9398599439775911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Rerun model\n",
    "lr = LogisticRegression(\n",
    "    )\n",
    "lr_bow = lr.fit(X_bow, Y_bow)\n",
    "print('BoW #3 - Logistic Regression Scores: ', cross_val_score(lr_bow, X_bow, Y_bow, cv=5))\n",
    "print('Avg. Score ', np.mean(cross_val_score(lr_bow, X_bow, Y_bow, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
